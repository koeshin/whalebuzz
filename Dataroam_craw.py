import pandas as pd
from playwright.sync_api import sync_playwright
import time
import random

# 1. ìˆ˜ì§‘ ëŒ€ìƒ ë¦¬ìŠ¤íŠ¸ (ì½”ë“œ, ìš´ìš©ì‚¬ëª…)
# Dataroma URLì˜ 'm=' ë’¤ì— ì˜¤ëŠ” ì½”ë“œë¥¼ ì…ë ¥í•©ë‹ˆë‹¤.
TARGET_GURUS = [
    {"code": "BRK", "name": "Warren Buffett (Berkshire)"},
    {"code": "PSC", "name": "Bill Ackman (Pershing Square)"},
    {"code": "AM",  "name": "David Tepper (Appaloosa)"},
    {"code": "IC",  "name": "Carl Icahn (Icahn Capital)"},
    {"code": "TP",  "name": "Daniel Loeb (Third Point)"},
    # í•„ìš”í•œ ë§Œí¼ ê³„ì† ì¶”ê°€ ê°€ëŠ¥
]

def scrape_all_gurus():
    all_data_frames = [] # ìˆ˜ì§‘ëœ ë°ì´í„°ë¥¼ ëª¨ì„ ë¦¬ìŠ¤íŠ¸

    with sync_playwright() as p:
        # ë¸Œë¼ìš°ì € ë„ìš°ê¸° (headless=True ê¶Œì¥)
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        page = context.new_page()

        print(f"ğŸš€ ì´ {len(TARGET_GURUS)}ëª…ì˜ í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ì§‘ì„ ì‹œì‘í•©ë‹ˆë‹¤.\n")

        for guru in TARGET_GURUS:
            code = guru["code"]
            name = guru["name"]
            url = f"https://www.dataroma.com/m/holdings.php?m={code}"
            
            print(f"[{name}] ë°ì´í„° ìˆ˜ì§‘ ì¤‘... ({url})")

            try:
                page.goto(url, timeout=30000)
                
                # í…Œì´ë¸” ë¡œë”© ëŒ€ê¸°
                page.wait_for_selector("#grid", timeout=10000)
                
                # HTML íŒŒì‹±
                html = page.content()
                dfs = pd.read_html(html)
                
                # í¬íŠ¸í´ë¦¬ì˜¤ í…Œì´ë¸” ê°€ì ¸ì˜¤ê¸° (ë³´í†µ ì²« ë²ˆì§¸ í˜¹ì€ ë‚´ìš©ì´ ê°€ì¥ ë§ì€ í…Œì´ë¸”)
                portfolio_df = dfs[0]

                # **í•µì‹¬: ëˆ„êµ¬ì˜ ë°ì´í„°ì¸ì§€ ì‹ë³„ì ì»¬ëŸ¼ ì¶”ê°€**
                portfolio_df.insert(0, "Manager_Code", code)
                portfolio_df.insert(1, "Manager_Name", name)
                
                # ìˆ˜ì§‘ ë‚ ì§œ(Reference) ì¶”ê°€ (ì‹¤ì œë¡œëŠ” 13F ë³´ê³  ê¸°ì¤€ì¼ì„ íŒŒì‹±í•´ì•¼ í•˜ì§€ë§Œ, ì§€ê¸ˆì€ ìˆ˜ì§‘ì¼ë¡œ ëŒ€ì²´)
                portfolio_df["Scraped_Date"] = pd.Timestamp.now().strftime("%Y-%m-%d")

                # ë¦¬ìŠ¤íŠ¸ì— ì¶”ê°€
                all_data_frames.append(portfolio_df)
                print(f"   âœ… ì„±ê³µ! ({len(portfolio_df)}ê°œ ì¢…ëª©)")

            except Exception as e:
                print(f"   âŒ ì‹¤íŒ¨: {e}")
            
            # ì°¨ë‹¨ ë°©ì§€ë¥¼ ìœ„í•œ ëœë¤ ë”œë ˆì´ (2~5ì´ˆ)
            time.sleep(random.uniform(2, 5))

        browser.close()

    # 2. ë°ì´í„° ë³‘í•© ë° ì €ì¥
    if all_data_frames:
        print("\nğŸ“Š ë°ì´í„° ë³‘í•© ì¤‘...")
        # ëª¨ë“  DataFrameì„ ìœ„ì•„ë˜ë¡œ í•©ì¹˜ê¸° (Concat)
        master_df = pd.concat(all_data_frames, ignore_index=True)
        
        # ê°„ë‹¨í•œ ì „ì²˜ë¦¬: ì»¬ëŸ¼ëª… ê³µë°± ì œê±°
        master_df.columns = [c.strip() for c in master_df.columns]

        # CSV ì €ì¥
        filename = "all_gurus_portfolio.csv"
        master_df.to_csv(filename, index=False, encoding="utf-8-sig") # ì—‘ì…€ ê¹¨ì§ ë°©ì§€(utf-8-sig)
        print(f"ğŸ‰ ì™„ë£Œ! '{filename}' íŒŒì¼ì— ì´ {len(master_df)}ê°œì˜ í–‰ì´ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        return master_df
    else:
        print("ìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

if __name__ == "__main__":
    scrape_all_gurus()