import pandas as pd
from playwright.sync_api import sync_playwright
from io import StringIO
import time
import random

# 1. 9ëŒ€ ê±°ì¸ ë¦¬ìŠ¤íŠ¸
TARGET_GURUS = [
    {"code": "BRK", "name": "Berkshire Hathaway", "style": "Value"},
    {"code": "BAUPOST", "name": "Baupost Group",       "style": "Value"},
    {"code": "SAM", "name": "Scion Asset Mgmt",    "style": "Value"},
    {"code": "TGM", "name": "Tiger Global",        "style": "Growth"},
    {"code": "COAT", "name": "Coatue Management",  "style": "Growth"}, 
    {"code": "DA",  "name": "Duquesne Family",     "style": "Growth"},
    {"code": "PSC", "name": "Pershing Square",     "style": "Activist"},
    {"code": "IC",  "name": "Icahn Enterprises",   "style": "Activist"},
    {"code": "TP",  "name": "Third Point",         "style": "Activist"},
]

# 2. ìˆ˜ì§‘í•  ê¸°ê°„ (2024ë…„ 1ë¶„ê¸° ~ 2025ë…„ 4ë¶„ê¸°)
# í˜„ì¬ ì‹œì (2026ë…„ 1ì›”) ê¸°ì¤€, ê³¼ê±° ë°ì´í„°ë¥¼ ëª¨ë‘ ë´…ë‹ˆë‹¤.
QUARTERS = [
    "2024-03-31", "2024-06-30", "2024-09-30", "2024-12-31",
    "2025-03-31", "2025-06-30", "2025-09-30", "2025-12-31"
]

def clean_number(value):
    """ë¬¸ìì—´($, %, ,)ì„ ìˆ«ì(float)ë¡œ ë³€í™˜í•˜ëŠ” í—¬í¼ í•¨ìˆ˜"""
    if isinstance(value, str):
        value = value.replace('$', '').replace('%', '').replace(',', '').strip()
        try:
            return float(value)
        except:
            return 0.0
    return value

def scrape_history_portfolios():
    all_dfs = []

    with sync_playwright() as p:
        browser = p.chromium.launch(headless=True)
        context = browser.new_context(
            user_agent="Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/91.0.4472.124 Safari/537.36"
        )
        page = context.new_page()

        print(f"â³ Time Machine ê°€ë™: ì´ {len(TARGET_GURUS)}ëª… * {len(QUARTERS)}ë¶„ê¸° ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘...\n")

        for guru in TARGET_GURUS:
            code = guru["code"]
            name = guru["name"]
            
            print(f"--- [{name}] History Scanning ---")

            for period in QUARTERS:
                # [í•µì‹¬] ë‚ ì§œ íŒŒë¼ë¯¸í„°(p)ë¥¼ URLì— ì¶”ê°€í•˜ì—¬ ê³¼ê±° ë°ì´í„° ì ‘ê·¼
                url = f"https://www.dataroma.com/m/holdings.php?m={code}&p={period}"
                
                try:
                    page.goto(url, timeout=20000)
                    
                    # ë°ì´í„°ê°€ ì—†ëŠ” ê²½ìš°(ì„¤ë¦½ ì „ì´ê±°ë‚˜ ë³´ê³  ëˆ„ë½ ë“±) ëŒ€ë¹„
                    try:
                        page.wait_for_selector("#grid", timeout=3000)
                    except:
                        print(f"   [Skip] {period}: ë°ì´í„° ì—†ìŒ (or ë¡œë”© ì‹¤íŒ¨)")
                        continue

                    html = page.content()
                    dfs = pd.read_html(StringIO(html))
                    raw_df = dfs[0]

                    # ì»¬ëŸ¼ ì¸ë±ìŠ¤ë¡œ ë°ì´í„° ì¶”ì¶œ (ì•ˆì „ì¥ì¹˜)
                    if len(raw_df.columns) >= 6:
                        df_subset = raw_df.iloc[:, :6].copy()
                        df_subset.columns = ['Stock_Name', 'Ticker', 'Weight_Pct', 'Shares', 'Price', 'Value']
                        
                        # ë©”íƒ€ë°ì´í„° ì¶”ê°€
                        df_subset.insert(0, "Manager", name)
                        df_subset.insert(1, "Style", guru["style"])
                        df_subset.insert(2, "Report_Date", period) # ê¸°ì¤€ì¼ì ì¤‘ìš”!
                        
                        # ë°ì´í„° ì •ì œ (ìˆ«ì ë³€í™˜)
                        df_subset['Weight_Pct'] = df_subset['Weight_Pct'].apply(clean_number)
                        df_subset['Value'] = df_subset['Value'].apply(clean_number)
                        # SharesëŠ” ê°€ë” ë¬¸ìê°€ ì„ì¼ ìˆ˜ ìˆì–´ ì²˜ë¦¬
                        df_subset['Shares'] = df_subset['Shares'].apply(clean_number)

                        all_dfs.append(df_subset)
                        print(f"   âœ… {period}: {len(df_subset)}ê°œ ì¢…ëª© ìˆ˜ì§‘")
                    
                    else:
                        print(f"   âš ï¸ {period}: í…Œì´ë¸” êµ¬ì¡° ì´ìƒ")

                except Exception as e:
                    print(f"   âŒ {period}: ì—ëŸ¬ ({e})")
                
                # ì„œë²„ ë¶€í•˜ ë°©ì§€ë¥¼ ìœ„í•œ ëœë¤ ë”œë ˆì´ (í•„ìˆ˜!)
                time.sleep(random.uniform(1.5, 3.0))

        browser.close()

    # ê²°ê³¼ ì €ì¥
    if all_dfs:
        print("\nğŸ“Š ë°ì´í„° ë³‘í•© ë° CSV ì €ì¥ ì¤‘...")
        master_df = pd.concat(all_dfs, ignore_index=True)
        
        # ë‚ ì§œìˆœ, ë§¤ë‹ˆì €ìˆœ ì •ë ¬
        master_df = master_df.sort_values(by=['Manager', 'Report_Date'])
        
        filename = "Guru_Portfolios_TimeSeries_2024-2025.csv"
        master_df.to_csv(filename, index=False, encoding="utf-8-sig")
        
        print(f"ğŸ‰ ë¯¸ì…˜ ì„±ê³µ! ì´ {len(master_df)}í–‰ì˜ ì‹œê³„ì—´ ë°ì´í„°ê°€ '{filename}'ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
        
        # ë¯¸ë¦¬ë³´ê¸° (ìƒìœ„ 5ê°œ)
        print(master_df.head())
        return master_df
    else:
        print("\nìˆ˜ì§‘ëœ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        return None

if __name__ == "__main__":
    scrape_history_portfolios()